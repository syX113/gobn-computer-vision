{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5084b478",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import random\n",
    "import os\n",
    "from collections import Counter\n",
    "from pathlib import Path\n",
    "from dotenv import load_dotenv\n",
    "from roboflow import Roboflow\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "roboflow_api_key = os.getenv(\"ROBOFLOW_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd1bfe04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download the dataset and the annotations\n",
    "rf = Roboflow(api_key=roboflow_api_key)\n",
    "project = rf.workspace(\"goldbach-neo-testspace\").project(\"stellenbilder\")\n",
    "version = project.version(4) # 3 Augmented, 4 Original\n",
    "dataset = version.download(\"coco-segmentation\")      "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "818d9ec1",
   "metadata": {},
   "source": [
    "# Dataset Analysis for Stellenbilder Instance Segmentation\n",
    "\n",
    "## Dataset Overview\n",
    "\n",
    "The dataset is organized in 3 directories:\n",
    "- **train**: Training images and annotations\n",
    "- **valid**: Validation images and annotations\n",
    "- **test**: Test images and annotations\n",
    "\n",
    "Each directory follows the COCO format with annotations in `_annotations.coco.json`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62c0f8f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to load COCO annotations\n",
    "def load_coco_annotations(annotation_file):\n",
    "    with open(annotation_file, 'r') as f:\n",
    "        return json.load(f)\n",
    "\n",
    "# Load annotations from all splits\n",
    "base_dir = Path(\"Stellenbilder-no-augs\")\n",
    "test_annotations = load_coco_annotations(base_dir / \"test\" / \"_annotations.coco.json\")\n",
    "train_annotations = load_coco_annotations(base_dir / \"train\" / \"_annotations.coco.json\")\n",
    "valid_annotations = load_coco_annotations(base_dir / \"valid\" / \"_annotations.coco.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7e70d4e",
   "metadata": {},
   "source": [
    "## Dataset Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f78b0bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to get dataset statistics\n",
    "def get_dataset_stats(annotations):\n",
    "    num_images = len(annotations['images'])\n",
    "    num_annotations = len(annotations['annotations'])\n",
    "    categories = {cat['id']: cat['name'] for cat in annotations['categories']}\n",
    "    \n",
    "    # Count instances per category\n",
    "    category_counts = Counter([ann['category_id'] for ann in annotations['annotations']])\n",
    "    category_stats = {categories[cat_id]: count for cat_id, count in category_counts.items()}\n",
    "    \n",
    "    # Calculate average annotations per image\n",
    "    avg_annotations_per_image = num_annotations / num_images if num_images > 0 else 0\n",
    "    \n",
    "    return {\n",
    "        'num_images': num_images,\n",
    "        'num_annotations': num_annotations,\n",
    "        'category_stats': category_stats,\n",
    "        'avg_annotations_per_image': avg_annotations_per_image\n",
    "    }\n",
    "\n",
    "# Get statistics for each split\n",
    "train_stats = get_dataset_stats(train_annotations)\n",
    "valid_stats = get_dataset_stats(valid_annotations)\n",
    "test_stats = get_dataset_stats(test_annotations)\n",
    "\n",
    "# Display statistics\n",
    "print(f\"Training set: {train_stats['num_images']} images, {train_stats['num_annotations']} annotations\")\n",
    "print(f\"Validation set: {valid_stats['num_images']} images, {valid_stats['num_annotations']} annotations\")\n",
    "print(f\"Test set: {test_stats['num_images']} images, {test_stats['num_annotations']} annotations\")\n",
    "print(\"\\nAverage annotations per image:\")\n",
    "print(f\"Training: {train_stats['avg_annotations_per_image']:.2f}\")\n",
    "print(f\"Validation: {valid_stats['avg_annotations_per_image']:.2f}\")\n",
    "print(f\"Test: {test_stats['avg_annotations_per_image']:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f09f9fb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize category distribution\n",
    "def plot_category_distribution(train_stats, valid_stats, test_stats):\n",
    "    categories = list(train_stats['category_stats'].keys())\n",
    "    train_counts = [train_stats['category_stats'].get(cat, 0) for cat in categories]\n",
    "    valid_counts = [valid_stats['category_stats'].get(cat, 0) for cat in categories]\n",
    "    test_counts = [test_stats['category_stats'].get(cat, 0) for cat in categories]\n",
    "    \n",
    "    x = np.arange(len(categories))\n",
    "    width = 0.25\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(12, 6))\n",
    "    ax.bar(x - width, train_counts, width, label='Train')\n",
    "    ax.bar(x, valid_counts, width, label='Validation')\n",
    "    ax.bar(x + width, test_counts, width, label='Test')\n",
    "    \n",
    "    ax.set_xlabel('Categories')\n",
    "    ax.set_ylabel('Number of Instances')\n",
    "    ax.set_title('Category Distribution across Dataset Splits')\n",
    "    ax.set_xticks(x)\n",
    "    ax.set_xticklabels(categories, rotation=45, ha='right')\n",
    "    ax.legend()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "plot_category_distribution(train_stats, valid_stats, test_stats)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53aa3797",
   "metadata": {},
   "source": [
    "## Sample Images with Annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a605974d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to visualize images with annotations\n",
    "def visualize_samples(annotations, img_dir, num_samples=3):\n",
    "    categories = {cat['id']: cat['name'] for cat in annotations['categories']}\n",
    "    image_ids = random.sample(range(len(annotations['images'])), min(num_samples, len(annotations['images'])))\n",
    "    \n",
    "    for idx, img_idx in enumerate(image_ids):\n",
    "        img_info = annotations['images'][img_idx]\n",
    "        img_path = os.path.join(img_dir, img_info['file_name'])\n",
    "        \n",
    "        # Load image\n",
    "        image = cv2.imread(img_path)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        # Get annotations for this image\n",
    "        img_anns = [ann for ann in annotations['annotations'] if ann['image_id'] == img_idx]\n",
    "        \n",
    "        # Setup figure\n",
    "        plt.figure(figsize=(12, 8))\n",
    "        plt.subplot(1, 2, 1)\n",
    "        plt.title(f\"Original Image: {img_info['file_name']}\")\n",
    "        plt.imshow(image)\n",
    "        plt.axis('off')\n",
    "        \n",
    "        # Create a copy for segmentation visualization\n",
    "        seg_img = image.copy()\n",
    "        \n",
    "        # Colors for different categories\n",
    "        colors = plt.cm.rainbow(np.linspace(0, 1, len(categories)))\n",
    "        \n",
    "        # Draw segmentations\n",
    "        for ann in img_anns:\n",
    "            category = categories[ann['category_id']]\n",
    "            color = (colors[ann['category_id'] % len(colors)] * 255).astype(np.uint8)[:3]\n",
    "            \n",
    "            # Convert to numpy array for OpenCV\n",
    "            color_tuple = (int(color[0]), int(color[1]), int(color[2]))\n",
    "            \n",
    "            # Draw segmentation mask\n",
    "            for seg in ann['segmentation']:\n",
    "                # Reshape points to format required by fillPoly\n",
    "                points = np.array(seg).reshape(-1, 2).astype(np.int32)\n",
    "                cv2.fillPoly(seg_img, [points], color_tuple)\n",
    "            \n",
    "            # Get bounding box coordinates\n",
    "            x, y, w, h = map(int, ann['bbox'])\n",
    "            \n",
    "            # Add label text\n",
    "            cv2.rectangle(seg_img, (x, y), (x + w, y + h), color_tuple, 2)\n",
    "            cv2.putText(seg_img, category, (x, y - 5), cv2.FONT_HERSHEY_SIMPLEX, 0.7, color_tuple, 2)\n",
    "        \n",
    "        # Show segmentation image\n",
    "        plt.subplot(1, 2, 2)\n",
    "        plt.title(\"Instance Segmentation\")\n",
    "        plt.imshow(seg_img)\n",
    "        plt.axis('off')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "# Visualize samples from each split\n",
    "print(\"Training samples:\")\n",
    "visualize_samples(train_annotations, base_dir / \"train\", num_samples=2)\n",
    "\n",
    "print(\"Validation samples:\")\n",
    "visualize_samples(valid_annotations, base_dir / \"valid\", num_samples=2)\n",
    "\n",
    "print(\"Test samples:\")\n",
    "visualize_samples(test_annotations, base_dir / \"test\", num_samples=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba46faa6",
   "metadata": {},
   "source": [
    "## Analysis of Object Sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6500421",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to analyze object sizes\n",
    "def analyze_object_sizes(annotations):\n",
    "    categories = {cat['id']: cat['name'] for cat in annotations['categories']}\n",
    "    \n",
    "    # Collect areas by category\n",
    "    category_areas = {cat_name: [] for cat_name in categories.values()}\n",
    "    \n",
    "    for ann in annotations['annotations']:\n",
    "        category = categories[ann['category_id']]\n",
    "        area = ann['area']\n",
    "        category_areas[category].append(area)\n",
    "    \n",
    "    # Plot area distributions\n",
    "    plt.figure(figsize=(14, 8))\n",
    "    \n",
    "    # Box plot for all categories\n",
    "    data = [areas for cat, areas in category_areas.items() if areas]\n",
    "    labels = [cat for cat, areas in category_areas.items() if areas]\n",
    "    \n",
    "    plt.boxplot(data, tick_labels=labels)\n",
    "    plt.title('Distribution of Object Areas by Category')\n",
    "    plt.ylabel('Area (pixels²)')\n",
    "    plt.xticks(rotation=45, ha='right')\n",
    "    plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Calculate statistics\n",
    "    stats = {}\n",
    "    for cat, areas in category_areas.items():\n",
    "        if areas:\n",
    "            stats[cat] = {\n",
    "                'min': min(areas),\n",
    "                'max': max(areas),\n",
    "                'mean': np.mean(areas),\n",
    "                'median': np.median(areas),\n",
    "                'count': len(areas)\n",
    "            }\n",
    "    \n",
    "    return stats\n",
    "\n",
    "# Analyze object sizes for all splits combined\n",
    "all_annotations = {\n",
    "    'images': train_annotations['images'] + valid_annotations['images'] + test_annotations['images'],\n",
    "    'annotations': train_annotations['annotations'] + valid_annotations['annotations'] + test_annotations['annotations'],\n",
    "    'categories': train_annotations['categories']\n",
    "}\n",
    "\n",
    "size_stats = analyze_object_sizes(all_annotations)\n",
    "\n",
    "# Print statistics\n",
    "print(\"Object Size Statistics by Category:\")\n",
    "for cat, stat in size_stats.items():\n",
    "    print(f\"{cat}: {stat['count']} instances, Mean area: {stat['mean']:.1f} px², Median: {stat['median']:.1f} px²\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f9759f2",
   "metadata": {},
   "source": [
    "## Color Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80389e98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to analyze color distributions in images\n",
    "def analyze_colors(annotations, img_dir, num_samples=3):\n",
    "    image_ids = random.sample(range(len(annotations['images'])), min(num_samples, len(annotations['images'])))\n",
    "    \n",
    "    for idx, img_idx in enumerate(image_ids):\n",
    "        img_info = annotations['images'][img_idx]\n",
    "        img_path = os.path.join(img_dir, img_info['file_name'])\n",
    "        \n",
    "        # Load image\n",
    "        image = cv2.imread(img_path)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        # Get annotations for this image\n",
    "        img_anns = [ann for ann in annotations['annotations'] if ann['image_id'] == img_idx]\n",
    "        \n",
    "        # Setup figure\n",
    "        plt.figure(figsize=(16, 6))\n",
    "        \n",
    "        # Show original image\n",
    "        plt.subplot(1, 4, 1)\n",
    "        plt.title(f\"Original Image\")\n",
    "        plt.imshow(image)\n",
    "        plt.axis('off')\n",
    "        \n",
    "        # Color histograms\n",
    "        colors = ('r', 'g', 'b')\n",
    "        channel_names = ('Red', 'Green', 'Blue')\n",
    "        \n",
    "        for i, color in enumerate(colors):\n",
    "            plt.subplot(1, 4, i+2)\n",
    "            histogram = cv2.calcHist([image], [i], None, [256], [0, 256])\n",
    "            plt.title(f'{channel_names[i]} Channel')\n",
    "            plt.xlim([0, 256])\n",
    "            plt.plot(histogram, color=color)\n",
    "            plt.grid(alpha=0.3)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "        # Calculate color statistics\n",
    "        print(f\"\\nColor statistics for {img_info['file_name']}:\")\n",
    "        for channel_idx, channel_name in enumerate(channel_names):\n",
    "            channel_values = image[:,:,channel_idx].flatten()\n",
    "            print(f\"{channel_name}: Mean = {np.mean(channel_values):.1f}, Std = {np.std(channel_values):.1f}, Min = {np.min(channel_values)}, Max = {np.max(channel_values)}\")\n",
    "\n",
    "# Analyze colors for a few test samples\n",
    "print(\"Color Analysis of Sample Images:\")\n",
    "analyze_colors(test_annotations, base_dir / \"test\", num_samples=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f240b41",
   "metadata": {},
   "source": [
    "## Object Aspect Ratio Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9306ab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to analyze object aspect ratios\n",
    "def analyze_aspect_ratios(annotations):\n",
    "    categories = {cat['id']: cat['name'] for cat in annotations['categories']}\n",
    "    \n",
    "    # Collect aspect ratios by category\n",
    "    category_aspect_ratios = {cat_name: [] for cat_name in categories.values()}\n",
    "    \n",
    "    for ann in annotations['annotations']:\n",
    "        category = categories[ann['category_id']]\n",
    "        x, y, width, height = ann['bbox']\n",
    "        \n",
    "        # Avoid division by zero\n",
    "        if height > 0:\n",
    "            aspect_ratio = width / height\n",
    "            category_aspect_ratios[category].append(aspect_ratio)\n",
    "    \n",
    "    # Plot aspect ratio distributions\n",
    "    plt.figure(figsize=(14, 8))\n",
    "    \n",
    "    data = [ratios for cat, ratios in category_aspect_ratios.items() if ratios]\n",
    "    labels = [cat for cat, ratios in category_aspect_ratios.items() if ratios]\n",
    "    \n",
    "    plt.boxplot(data, tick_labels=labels)\n",
    "    plt.axhline(y=1.0, color='r', linestyle='--', alpha=0.7, label='Square (w=h)')\n",
    "    plt.title('Distribution of Object Aspect Ratios by Category')\n",
    "    plt.ylabel('Aspect Ratio (width/height)')\n",
    "    plt.xticks(rotation=45, ha='right')\n",
    "    plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Calculate statistics\n",
    "    stats = {}\n",
    "    for cat, ratios in category_aspect_ratios.items():\n",
    "        if ratios:\n",
    "            stats[cat] = {\n",
    "                'min': min(ratios),\n",
    "                'max': max(ratios),\n",
    "                'mean': np.mean(ratios),\n",
    "                'median': np.median(ratios),\n",
    "                'count': len(ratios)\n",
    "            }\n",
    "    \n",
    "    return stats\n",
    "\n",
    "# Analyze aspect ratios for all splits combined\n",
    "aspect_ratio_stats = analyze_aspect_ratios(all_annotations)\n",
    "\n",
    "# Print statistics\n",
    "print(\"Object Aspect Ratio Statistics by Category:\")\n",
    "for cat, stat in aspect_ratio_stats.items():\n",
    "    print(f\"{cat}: Mean ratio: {stat['mean']:.2f}, Median ratio: {stat['median']:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e6f12ad",
   "metadata": {},
   "source": [
    "## Spatial Distribution Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a94766c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to analyze spatial distribution of objects\n",
    "def analyze_spatial_distribution(annotations):\n",
    "    categories = {cat['id']: cat['name'] for cat in annotations['categories']}\n",
    "    \n",
    "    # Extract center points of all bounding boxes\n",
    "    all_centers = []\n",
    "    category_centers = {cat_name: [] for cat_name in categories.values()}\n",
    "    \n",
    "    # Standard image width and height from the dataset (assuming all images are same size)\n",
    "    img_width = annotations['images'][0]['width']\n",
    "    img_height = annotations['images'][0]['height']\n",
    "    \n",
    "    for ann in annotations['annotations']:\n",
    "        category = categories[ann['category_id']]\n",
    "        x, y, width, height = ann['bbox']\n",
    "        \n",
    "        # Calculate center in normalized coordinates (0-1)\n",
    "        center_x = (x + width/2) / img_width\n",
    "        center_y = (y + height/2) / img_height\n",
    "        \n",
    "        all_centers.append((center_x, center_y))\n",
    "        category_centers[category].append((center_x, center_y))\n",
    "    \n",
    "    # Plot all centers\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    \n",
    "    # Get all x and y coordinates\n",
    "    all_x = [c[0] for c in all_centers]\n",
    "    all_y = [c[1] for c in all_centers]\n",
    "    \n",
    "    # Create heatmap-like visualization\n",
    "    plt.hist2d(all_x, all_y, bins=20, cmap='hot')\n",
    "    plt.colorbar(label='Number of objects')\n",
    "    \n",
    "    plt.title('Spatial Distribution of All Objects')\n",
    "    plt.xlabel('Normalized X Position')\n",
    "    plt.ylabel('Normalized Y Position')\n",
    "    \n",
    "    # Draw image boundaries\n",
    "    plt.axhline(y=0, color='black', linestyle='-', alpha=0.3)\n",
    "    plt.axhline(y=1, color='black', linestyle='-', alpha=0.3)\n",
    "    plt.axvline(x=0, color='black', linestyle='-', alpha=0.3)\n",
    "    plt.axvline(x=1, color='black', linestyle='-', alpha=0.3)\n",
    "    \n",
    "    plt.xlim(0, 1)\n",
    "    plt.ylim(0, 1)\n",
    "    plt.gca().invert_yaxis()  # Invert Y axis to match image coordinates\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Plot per category (top N categories with most instances)\n",
    "    top_categories = sorted([(cat, len(centers)) for cat, centers in category_centers.items() if centers], key=lambda x: x[1], reverse=True)[:3]\n",
    "    \n",
    "    if top_categories:\n",
    "        fig, axes = plt.subplots(1, len(top_categories), figsize=(15, 5))\n",
    "        if len(top_categories) == 1:\n",
    "            axes = [axes]\n",
    "            \n",
    "        for i, (category, _) in enumerate(top_categories):\n",
    "            centers = category_centers[category]\n",
    "            x = [c[0] for c in centers]\n",
    "            y = [c[1] for c in centers]\n",
    "            \n",
    "            axes[i].scatter(x, y, alpha=0.5)\n",
    "            axes[i].set_title(f'Distribution: {category}')\n",
    "            axes[i].set_xlabel('Normalized X Position')\n",
    "            axes[i].set_ylabel('Normalized Y Position')\n",
    "            axes[i].set_xlim(0, 1)\n",
    "            axes[i].set_ylim(0, 1)\n",
    "            axes[i].invert_yaxis()  # Invert Y axis to match image coordinates\n",
    "            \n",
    "            # Draw image boundaries\n",
    "            axes[i].axhline(y=0, color='black', linestyle='-', alpha=0.3)\n",
    "            axes[i].axhline(y=1, color='black', linestyle='-', alpha=0.3)\n",
    "            axes[i].axvline(x=0, color='black', linestyle='-', alpha=0.3)\n",
    "            axes[i].axvline(x=1, color='black', linestyle='-', alpha=0.3)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "analyze_spatial_distribution(all_annotations)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "c-venv-gobn-cv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
