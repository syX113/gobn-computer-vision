{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "13fd57cc",
   "metadata": {},
   "source": [
    "# Color-Based Pixel Cluster Detection\n",
    "\n",
    "Implements a detector for specific color clusters (Grey: `#b2b2b2`, Red: `#bc1c31`) in images. It includes:\n",
    "- Centralized configuration for parameters.\n",
    "- Image loading and display.\n",
    "- An exact HEX/RGB color matching algorithm.\n",
    "- Connected component analysis to identify clusters.\n",
    "- Filtering clusters by minimum area.\n",
    "- Comprehensive visualizations of intermediate steps and final results.\n",
    "- A simple hyperparameter tuning example for `min_cluster_area`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef00bae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "import json\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import defaultdict\n",
    "from tqdm.notebook import tqdm\n",
    "from skimage import measure # For connected component analysis\n",
    "from skimage.color import label2rgb\n",
    "from PIL import ImageColor # Pillow for HEX to RGB and potentially image loading\n",
    "\n",
    "# Target colors\n",
    "TARGET_COLORS_HEX = {\n",
    "    'Grey': '#b2b2b2',\n",
    "    'Red': '#b81f34' }\n",
    "\n",
    "# Convert HEX to RGB tuples\n",
    "TARGET_COLORS_RGB = {name: ImageColor.getrgb(hex_val) for name, hex_val in TARGET_COLORS_HEX.items()}\n",
    "print(f\"Target RGB Colors: {TARGET_COLORS_RGB}\")\n",
    "\n",
    "# Image paths (relative to the notebook location)\n",
    "BASE_IMAGE_DIR = 'Stellenbilder-no-augs/train/' \n",
    "\n",
    "# Attempt to find a sample image, or use a placeholder\n",
    "image_files_in_dir = glob.glob(os.path.join(BASE_IMAGE_DIR, '*.jpg'))\n",
    "if image_files_in_dir:\n",
    "    SAMPLE_IMAGE_NAME = os.path.basename(image_files_in_dir[0])\n",
    "else:\n",
    "    SAMPLE_IMAGE_NAME = 'YOUR_SAMPLE_IMAGE.jpg' # Placeholder if no images found\n",
    "    print(f\"Warning: No JPG images found in {BASE_IMAGE_DIR}. Please set SAMPLE_IMAGE_NAME manually.\")\n",
    "\n",
    "SAMPLE_IMAGE_PATH = os.path.join(BASE_IMAGE_DIR, SAMPLE_IMAGE_NAME)\n",
    "print(f\"Using sample image: {SAMPLE_IMAGE_PATH}\")\n",
    "\n",
    "# Hyperparameters for tuning\n",
    "HYPERPARAMS = {\n",
    "    'min_cluster_area_range': [200, 500, 750, 1000, 1250, 1500, 1750, 2000, 2250, 2500] # Amount of pixels\n",
    "}\n",
    "\n",
    "# Default minimum area \n",
    "DEFAULT_MIN_AREA = 199 # Pixels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58f97f3f",
   "metadata": {},
   "source": [
    "## 2. Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4598292",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image_rgb(image_path):\n",
    "    \"\"\"Loads an image using OpenCV and converts it from BGR to RGB.\"\"\"\n",
    "    if not os.path.exists(image_path):\n",
    "        print(f\"Error: Image not found at {image_path}\")\n",
    "        return None\n",
    "    try:\n",
    "        img_bgr = cv2.imread(image_path)\n",
    "        if img_bgr is None:\n",
    "            print(f\"Error: OpenCV could not read image at {image_path}\")\n",
    "            return None\n",
    "        img_rgb = cv2.cvtColor(img_bgr, cv2.COLOR_BGR2RGB)\n",
    "        return img_rgb\n",
    "    except Exception as e:\n",
    "        print(f\"Exception while loading image {image_path}: {e}\")\n",
    "        return None\n",
    "\n",
    "def display_image(image, title=\"\", cmap=None, figsize=(8, 6)):\n",
    "    \"\"\"Displays an image using Matplotlib.\"\"\"\n",
    "    if image is None:\n",
    "        print(\"Cannot display None image.\")\n",
    "        return\n",
    "    plt.figure(figsize=figsize)\n",
    "    plt.imshow(image, cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "def display_images_side_by_side(images, titles, figsize=(15, 7), cmap=None):\n",
    "    \"\"\"Displays multiple images side-by-side.\"\"\"\n",
    "    if not images or not titles or len(images) != len(titles):\n",
    "        print(\"Invalid input for display_images_side_by_side\")\n",
    "        return\n",
    "    \n",
    "    count = len(images)\n",
    "    fig, axes = plt.subplots(1, count, figsize=figsize)\n",
    "    if count == 1:\n",
    "        axes = [axes]\n",
    "        \n",
    "    for i in range(count):\n",
    "        if images[i] is not None:\n",
    "            axes[i].imshow(images[i], cmap=cmap if len(images[i].shape) == 2 else None) # Apply cmap only for 2D arrays\n",
    "            axes[i].set_title(titles[i])\n",
    "        axes[i].axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def detect_exact_color_clusters(image_rgb, target_rgb_color, min_area=100):\n",
    "\n",
    "    if image_rgb is None:\n",
    "        return []\n",
    "    \n",
    "    # Create a binary mask where pixels match the target_rgb_color exactly\n",
    "    binary_mask = np.all(image_rgb == target_rgb_color, axis=-1)\n",
    "    \n",
    "    if not np.any(binary_mask): # No pixels of the target color found\n",
    "        return []\n",
    "        \n",
    "    # Label connected regions (clusters) in the binary mask\n",
    "    labeled_mask, num_labels = measure.label(binary_mask, connectivity=2, background=0, return_num=True)\n",
    "    \n",
    "    if num_labels == 0:\n",
    "        return []\n",
    "        \n",
    "    # Get properties of each labeled region\n",
    "    regions = measure.regionprops(labeled_mask)\n",
    "    \n",
    "    detected_clusters = []\n",
    "    for region in regions:\n",
    "        if region.area >= min_area:\n",
    "            detected_clusters.append({\n",
    "                'label': region.label,\n",
    "                'bbox': region.bbox,  # (min_row, min_col, max_row, max_col)\n",
    "                'area': region.area,\n",
    "                'centroid': region.centroid # (row, col)\n",
    "            })\n",
    "            \n",
    "    return detected_clusters\n",
    "\n",
    "def draw_detections_on_image(image_rgb, detections, color_name_label, box_color_rgb=(0, 255, 0)):\n",
    "\n",
    "    if image_rgb is None:\n",
    "        return None\n",
    "    output_image = image_rgb.copy()\n",
    "    \n",
    "    # OpenCV expects BGR for drawing colors, so convert box_color_rgb\n",
    "    box_color_bgr = tuple(reversed(box_color_rgb))\n",
    "\n",
    "    for det in detections:\n",
    "        min_r, min_c, max_r, max_c = det['bbox']\n",
    "        area = det['area']\n",
    "        \n",
    "        # Draw bounding box\n",
    "        cv2.rectangle(output_image, (min_c, min_r), (max_c, max_r), box_color_bgr, 2)\n",
    "        \n",
    "        # Prepare text label\n",
    "        label_text = f\"{color_name_label} (Area: {area})\"\n",
    "        \n",
    "        # Put text above the bounding box\n",
    "        text_y_pos = min_r - 10 if min_r - 10 > 10 else min_r + 20\n",
    "        cv2.putText(output_image, label_text, (min_c, text_y_pos), \n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.5, box_color_bgr, 1, cv2.LINE_AA)\n",
    "            \n",
    "    return output_image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8955bfcd",
   "metadata": {},
   "source": [
    "## 3. Load and Display a Sample Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fee83a31",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_image_rgb = load_image_rgb(SAMPLE_IMAGE_PATH)\n",
    "\n",
    "if sample_image_rgb is not None:\n",
    "    display_image(sample_image_rgb, title=f\"Sample Image: {SAMPLE_IMAGE_NAME}\")\n",
    "else:\n",
    "    print(f\"Failed to load sample image. Please check the path: {SAMPLE_IMAGE_PATH}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "105efa79",
   "metadata": {},
   "source": [
    "## 4. How the Color Detector Works\n",
    "\n",
    "The process involves:\n",
    "1.  **Binary Mask Creation:** Identify all pixels that exactly match the target RGB color.\n",
    "2.  **Connected Component Labeling:** Group adjacent matching pixels into clusters (regions).\n",
    "3.  **Region Property Analysis & Filtering:** Calculate properties (like area) for each cluster and filter out small, potentially noisy clusters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fccb6363",
   "metadata": {},
   "outputs": [],
   "source": [
    "if sample_image_rgb is not None:\n",
    "    target_color_name = 'Grey' # Or 'Red'\n",
    "    target_rgb_value = TARGET_COLORS_RGB[target_color_name]\n",
    "    print(f\"--- Analyzing for color: {target_color_name} ({target_rgb_value}) ---\")\n",
    "\n",
    "    # 1. Create Binary Mask\n",
    "    binary_mask_for_target = np.all(sample_image_rgb == target_rgb_value, axis=-1)\n",
    "    display_image(binary_mask_for_target.astype(np.uint8) * 255, title=f\"1. Binary Mask for {target_color_name} ({target_rgb_value})\", cmap='Pastel1')\n",
    "\n",
    "    # 2. Label Connected Components\n",
    "    if np.any(binary_mask_for_target):\n",
    "        labeled_mask, num_labels = measure.label(binary_mask_for_target, connectivity=2, background=0, return_num=True)\n",
    "        print(f\"Found {num_labels} initial connected components (clusters) for {target_color_name}.\")\n",
    "        \n",
    "        # Visualize labeled components with colors\n",
    "        colored_labeled_mask = label2rgb(labeled_mask, image=sample_image_rgb, bg_label=0, kind='overlay')\n",
    "        display_image(colored_labeled_mask, title=f\"2. Labeled Components for {target_color_name} (Before Area Filtering)\")\n",
    "    else:\n",
    "        print(f\"No pixels found for {target_color_name}. Skipping labeling and filtering visualization.\")\n",
    "        labeled_mask = None\n",
    "        num_labels = 0\n",
    "\n",
    "    # 3. Region Property Analysis & Filtering\n",
    "    if labeled_mask is not None and num_labels > 0:\n",
    "        regions = measure.regionprops(labeled_mask)\n",
    "        print(f\"--- Region Properties (before filtering by area={DEFAULT_MIN_AREA}) ---\")\n",
    "        for i, region in enumerate(regions[:5]):\n",
    "            print(f\"  Region {region.label}: Area={region.area}, BBox={region.bbox}\")\n",
    "        if len(regions) > 5:\n",
    "            print(\"  ... and more regions.\")\n",
    "\n",
    "        # Filter by min_area\n",
    "        filtered_detections = []\n",
    "        for region in regions:\n",
    "            if region.area >= DEFAULT_MIN_AREA:\n",
    "                filtered_detections.append({\n",
    "                    'label': region.label, 'bbox': region.bbox, \n",
    "                    'area': region.area, 'centroid': region.centroid\n",
    "                })\n",
    "        \n",
    "        print(f\"Found {len(filtered_detections)} clusters for {target_color_name} after filtering by min_area >= {DEFAULT_MIN_AREA} pixels.\")\n",
    "\n",
    "        # Visualize detections after filtering\n",
    "        image_with_filtered_detections = draw_detections_on_image(sample_image_rgb, \n",
    "                                                                  filtered_detections, \n",
    "                                                                  target_color_name,\n",
    "                                                                  box_color_rgb=(255,0,0))\n",
    "        if image_with_filtered_detections is not None:\n",
    "            display_image(image_with_filtered_detections, \n",
    "                          title=f\"3. {target_color_name} Detections (min_area={DEFAULT_MIN_AREA})\")\n",
    "    else:\n",
    "        print(f\"No components to filter for {target_color_name}.\")\n",
    "else:\n",
    "    print(\"Sample image not loaded, skipping deep dive.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e24c6bb",
   "metadata": {},
   "source": [
    "## 5. Applying Detector and Visualizing Results for All Target Colors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0927549f",
   "metadata": {},
   "outputs": [],
   "source": [
    "if sample_image_rgb is not None:\n",
    "    image_to_draw_on = sample_image_rgb.copy()\n",
    "    all_detections_combined = []\n",
    "    \n",
    "    bbox_draw_colors = {\n",
    "        'Grey': (0, 0, 255),\n",
    "        'Red': (0, 255, 0)}\n",
    "\n",
    "    for color_name, target_rgb in TARGET_COLORS_RGB.items():\n",
    "        print(f\"Detecting '{color_name}' clusters (RGB: {target_rgb}, Min Area: {DEFAULT_MIN_AREA})...\")\n",
    "        detections = detect_exact_color_clusters(sample_image_rgb, target_rgb, min_area=DEFAULT_MIN_AREA)\n",
    "        print(f\"Found {len(detections)} '{color_name}' clusters.\")\n",
    "        all_detections_combined.extend(detections)\n",
    "        \n",
    "        draw_color_for_bbox = bbox_draw_colors.get(color_name, (255,255,0))\n",
    "        image_to_draw_on = draw_detections_on_image(image_to_draw_on, detections, color_name, draw_color_for_bbox)\n",
    "\n",
    "    if image_to_draw_on is not None:\n",
    "        display_image(image_to_draw_on, title=f\"All Detected Clusters (min_area={DEFAULT_MIN_AREA})\")\n",
    "    \n",
    "    masks_to_show = []\n",
    "    mask_titles = []\n",
    "    for color_name, target_rgb in TARGET_COLORS_RGB.items():\n",
    "        mask = np.all(sample_image_rgb == target_rgb, axis=-1).astype(np.uint8) * 255\n",
    "        masks_to_show.append(mask)\n",
    "        mask_titles.append(f\"Mask for {color_name}\")\n",
    "    \n",
    "    if masks_to_show:\n",
    "        display_images_side_by_side(masks_to_show, mask_titles, cmap='gray')\n",
    "else:\n",
    "    print(\"Sample image not loaded, skipping detection visualization.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11c7c958",
   "metadata": {},
   "source": [
    "## 6. Hyperparameter Tuning: Minimum Cluster Area (`min_cluster_area`)\n",
    "\n",
    "The `min_cluster_area` parameter helps filter out small, potentially irrelevant pixel groups."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ccdcb86",
   "metadata": {},
   "outputs": [],
   "source": [
    "if sample_image_rgb is not None:\n",
    "    min_area_values = HYPERPARAMS['min_cluster_area_range']\n",
    "    \n",
    "    cluster_counts_by_area = {color_name: [] for color_name in TARGET_COLORS_RGB}\n",
    "\n",
    "    for area_thresh in min_area_values:\n",
    "        print(f\"Testing min_area = {area_thresh} pixels...\")\n",
    "        for color_name, target_rgb in TARGET_COLORS_RGB.items():\n",
    "            detections = detect_exact_color_clusters(sample_image_rgb, target_rgb, min_area=area_thresh)\n",
    "            cluster_counts_by_area[color_name].append(len(detections))\n",
    "\n",
    "    plt.figure(figsize=(12, 7))\n",
    "    for color_name, counts in cluster_counts_by_area.items():\n",
    "        plt.plot(min_area_values, counts, marker='o', linestyle='-', label=f'{color_name} Clusters')\n",
    "        for i, count_val in enumerate(counts):\n",
    "            max_val_for_offset = max(max(v) for v in cluster_counts_by_area.values()) if any(any(v) for v in cluster_counts_by_area.values()) else 1\n",
    "            plt.text(min_area_values[i], count_val + (0.02 * max_val_for_offset) , str(count_val), ha='center', va='bottom', fontsize=9)\n",
    "\n",
    "    plt.xlabel(\"Minimum Cluster Area (pixels)\")\n",
    "    plt.ylabel(\"Number of Detected Clusters\")\n",
    "    plt.title(\"Effect of Minimum Cluster Area on Detections (Sample Image)\")\n",
    "    plt.legend()\n",
    "    plt.grid(True, which=\"both\", ls=\"--\", c='0.7')\n",
    "    plt.xticks(min_area_values)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"--- Summary of Cluster Counts ---\")\n",
    "    for color_name in TARGET_COLORS_RGB:\n",
    "        print(f\"Color: {color_name}\")\n",
    "        for i, area_val in enumerate(min_area_values):\n",
    "            print(f\"  Min Area: {area_val:4d} pixels -> Clusters: {cluster_counts_by_area[color_name][i]}\")\n",
    "else:\n",
    "    print(\"Sample image not loaded, skipping hyperparameter tuning.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba018ab0",
   "metadata": {},
   "source": [
    "## 7. Batch Processing: Applying to Multiple Images\n",
    "\n",
    "apply the detector with a chosen `min_cluster_area` (e.g., selected based on the tuning plot above) to a few more images from the dataset to see how it performs more broadly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8949e7c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Using CHOSEN_MIN_AREA = {DEFAULT_MIN_AREA} for batch processing.\")\n",
    "\n",
    "if os.path.exists(BASE_IMAGE_DIR):\n",
    "    all_image_files = glob.glob(os.path.join(BASE_IMAGE_DIR, '*.jpg'))\n",
    "    num_images_to_process = min(5, len(all_image_files))\n",
    "    \n",
    "    if num_images_to_process == 0:\n",
    "        print(f\"No JPG images found in {BASE_IMAGE_DIR} for batch processing.\")\n",
    "    else:\n",
    "        selected_image_files = all_image_files[:num_images_to_process]\n",
    "        print(f\"Processing {num_images_to_process} images...\")\n",
    "\n",
    "        for img_path in selected_image_files:\n",
    "            print(f\"--- Processing: {os.path.basename(img_path)} ---\")\n",
    "            current_image_rgb = load_image_rgb(img_path)\n",
    "            \n",
    "            if current_image_rgb is None:\n",
    "                print(f\"Skipping {os.path.basename(img_path)} due to loading error.\")\n",
    "                continue\n",
    "\n",
    "            image_with_all_detections = current_image_rgb.copy()\n",
    "            \n",
    "            bbox_draw_colors_batch = {\n",
    "                'Grey': (0, 0, 255),\n",
    "                'Red': (0, 255, 0)\n",
    "            }\n",
    "\n",
    "            any_detections_on_image = False\n",
    "            for color_name, target_rgb in TARGET_COLORS_RGB.items():\n",
    "                detections = detect_exact_color_clusters(current_image_rgb, target_rgb, min_area=DEFAULT_MIN_AREA)\n",
    "                print(f\"  Found {len(detections)} '{color_name}' clusters.\")\n",
    "                if detections:\n",
    "                    any_detections_on_image = True\n",
    "                \n",
    "                draw_color = bbox_draw_colors_batch.get(color_name, (255,255,0))\n",
    "                image_with_all_detections = draw_detections_on_image(image_with_all_detections, \n",
    "                                                                     detections, \n",
    "                                                                     color_name, \n",
    "                                                                     draw_color)\n",
    "            \n",
    "            if image_with_all_detections is not None:\n",
    "                display_title = f\"Detections on {os.path.basename(img_path)} (min_area={DEFAULT_MIN_AREA})\"\n",
    "                if not any_detections_on_image:\n",
    "                    display_title += \" - No clusters found\"\n",
    "                display_image(image_with_all_detections, title=display_title, figsize=(10,8))\n",
    "else:\n",
    "    print(f\"Image directory {BASE_IMAGE_DIR} not found. Skipping batch processing.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cf699eb",
   "metadata": {},
   "source": [
    "## 8. Evaluation: Comparing Detector Results with Ground Truth from COCO Annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08bb8ac3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to load COCO annotations and extract object counts per image\n",
    "def load_coco_annotations(annotation_file):\n",
    "    \"\"\"Load COCO annotations and return a dictionary mapping image_id to object count\"\"\"\n",
    "    if not os.path.exists(annotation_file):\n",
    "        print(f\"Annotation file not found: {annotation_file}\")\n",
    "        return None\n",
    "    \n",
    "    try:\n",
    "        with open(annotation_file, 'r') as f:\n",
    "            annotations = json.load(f)\n",
    "        \n",
    "        # Create mapping from image_id to file name\n",
    "        image_id_to_filename = {}\n",
    "        for image in annotations['images']:\n",
    "            image_id_to_filename[image['id']] = image['file_name']\n",
    "        \n",
    "        # Count objects per image\n",
    "        object_counts = defaultdict(int)\n",
    "        for ann in annotations['annotations']:\n",
    "            image_id = ann['image_id']\n",
    "            object_counts[image_id] += 1\n",
    "        \n",
    "        # Map filename to object count\n",
    "        filename_to_object_count = {}\n",
    "        for image_id, count in object_counts.items():\n",
    "            if image_id in image_id_to_filename:\n",
    "                filename = image_id_to_filename[image_id]\n",
    "                filename_to_object_count[filename] = count\n",
    "        \n",
    "        return filename_to_object_count\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error loading COCO annotations: {e}\")\n",
    "        return None\n",
    "\n",
    "# Set the dataset path\n",
    "DATASET_PATH = 'Stellenbilder-no-augs'  # 'Stellenbilder-augmented' for the augmented dataset\n",
    "\n",
    "# Load annotations for each split\n",
    "splits = ['train', 'valid', 'test']\n",
    "annotations_by_split = {}\n",
    "\n",
    "for split in splits:\n",
    "    annotation_file = os.path.join(DATASET_PATH, split, '_annotations.coco.json')\n",
    "    print(f\"Loading annotations from {annotation_file}...\")\n",
    "    annotations_by_split[split] = load_coco_annotations(annotation_file)\n",
    "    if annotations_by_split[split]:\n",
    "        print(f\"Loaded {len(annotations_by_split[split])} image annotations for {split} split\")\n",
    "    else:\n",
    "        print(f\"Failed to load annotations for {split} split\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66a64a72",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_split = 'train'\n",
    "test_images_dir = os.path.join(DATASET_PATH, test_split)\n",
    "test_annotations = annotations_by_split[test_split]\n",
    "\n",
    "if not test_annotations:\n",
    "    print(\"Test annotations not available. Cannot proceed with evaluation.\")\n",
    "else:\n",
    "    # Function to run detector on an image and return detection counts\n",
    "    def evaluate_image_with_detector(image_path, min_area=DEFAULT_MIN_AREA):\n",
    "        \"\"\"Run the detector on an image and return counts per target color\"\"\"\n",
    "        image_rgb = load_image_rgb(image_path)\n",
    "        if image_rgb is None:\n",
    "            return None\n",
    "        \n",
    "        # Initialize detection results\n",
    "        detection_results = {}\n",
    "        total_detections = 0\n",
    "        \n",
    "        # Run detector for each target color\n",
    "        for color_name, target_rgb in TARGET_COLORS_RGB.items():\n",
    "            detections = detect_exact_color_clusters(image_rgb, target_rgb, min_area=min_area)\n",
    "            detection_results[color_name] = len(detections)\n",
    "            total_detections += len(detections)\n",
    "        \n",
    "        detection_results['total'] = total_detections\n",
    "        return detection_results\n",
    "    \n",
    "    # Prepare data structure for evaluation results\n",
    "    evaluation_results = []\n",
    "    \n",
    "    # Get list of test images\n",
    "    test_image_files = []\n",
    "    for filename in test_annotations.keys():\n",
    "        file_path = os.path.join(test_images_dir, filename)\n",
    "        if os.path.exists(file_path):\n",
    "            test_image_files.append((filename, file_path))\n",
    "    \n",
    "    print(f\"Found {len(test_image_files)} test images with annotations\")\n",
    "    \n",
    "    # Run evaluation on test images\n",
    "    print(f\"Running evaluation with min_area={DEFAULT_MIN_AREA}...\")\n",
    "    for filename, file_path in tqdm(test_image_files, desc=\"Evaluating images\"):\n",
    "        # Get ground truth count\n",
    "        gt_count = test_annotations.get(filename, 0)\n",
    "        \n",
    "        # Run detector\n",
    "        detection_results = evaluate_image_with_detector(file_path)\n",
    "        \n",
    "        if detection_results is not None:\n",
    "            # Store results\n",
    "            result = {\n",
    "                'filename': filename,\n",
    "                'ground_truth_count': gt_count,\n",
    "                'detected_total': detection_results['total']\n",
    "            }\n",
    "            # Add individual color counts\n",
    "            for color_name in TARGET_COLORS_RGB.keys():\n",
    "                result[f'detected_{color_name}'] = detection_results.get(color_name, 0)\n",
    "            \n",
    "            evaluation_results.append(result)\n",
    "    \n",
    "    eval_df = pd.DataFrame(evaluation_results)\n",
    "    \n",
    "    # Display summary statistics\n",
    "    print(\"\\nEvaluation Summary:\")\n",
    "    print(f\"Number of evaluated images: {len(eval_df)}\")\n",
    "    print(f\"Average ground truth objects per image: {eval_df['ground_truth_count'].mean():.2f}\")\n",
    "    print(f\"Average detected objects per image: {eval_df['detected_total'].mean():.2f}\")\n",
    "    \n",
    "    # Calculate detection difference (error)\n",
    "    eval_df['detection_diff'] = eval_df['detected_total'] - eval_df['ground_truth_count']\n",
    "    eval_df['detection_error'] = eval_df['detection_diff'].abs()\n",
    "    eval_df['detection_error_pct'] = (eval_df['detection_error'] / eval_df['ground_truth_count']) * 100\n",
    "    eval_df['detection_error_pct'] = eval_df['detection_error_pct'].fillna(0)\n",
    "    \n",
    "    # Display more statistics\n",
    "    print(f\"Average absolute detection error: {eval_df['detection_error'].mean():.2f} objects\")\n",
    "    print(f\"Median absolute detection error: {eval_df['detection_error'].median():.2f} objects\")\n",
    "    print(f\"Average detection error percentage: {eval_df['detection_error_pct'].mean():.2f}%\")\n",
    "    \n",
    "    # Display the first few results\n",
    "    print(\"\\nSample evaluation results:\")\n",
    "    print(eval_df[['filename', 'ground_truth_count', 'detected_total', 'detection_diff']].head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38fd8f2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the evaluation results\n",
    "if 'eval_df' in locals() and not eval_df.empty:\n",
    "    plt.figure(figsize=(15, 10))\n",
    "    plt.subplot(2, 2, 1)\n",
    "    \n",
    "    # 1. Scatter plot of ground truth vs detected\n",
    "    plt.scatter(eval_df['ground_truth_count'], eval_df['detected_total'], alpha=0.6)\n",
    "    # Add perfect prediction line\n",
    "    max_count = max(eval_df['ground_truth_count'].max(), eval_df['detected_total'].max())\n",
    "    plt.plot([0, max_count], [0, max_count], 'r--', label='Perfect Detection')\n",
    "    plt.xlabel('Ground Truth Object Count')\n",
    "    plt.ylabel('Detected Object Count')\n",
    "    plt.title('Ground Truth vs Detected Objects')\n",
    "    plt.grid(True, linestyle='--', alpha=0.7)\n",
    "    plt.legend()\n",
    "    \n",
    "    # 2. Histogram of detection difference\n",
    "    plt.subplot(2, 2, 2)\n",
    "    sns.histplot(eval_df['detection_diff'], kde=True)\n",
    "    plt.axvline(x=0, color='r', linestyle='--', label='Perfect Detection')\n",
    "    plt.xlabel('Detection Difference (Detected - Ground Truth)')\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.title('Detection Error Distribution')\n",
    "    plt.grid(True, linestyle='--', alpha=0.7)\n",
    "    plt.legend()\n",
    "    \n",
    "    # 3. Bar chart of error by ground truth count\n",
    "    plt.subplot(2, 2, 3)\n",
    "    # Group by ground truth count and get mean error\n",
    "    error_by_count = eval_df.groupby('ground_truth_count')['detection_error'].mean().reset_index()\n",
    "    # Sort by ground truth count for better visualization\n",
    "    error_by_count = error_by_count.sort_values('ground_truth_count')\n",
    "    plt.bar(error_by_count['ground_truth_count'], error_by_count['detection_error'])\n",
    "    plt.xlabel('Ground Truth Object Count')\n",
    "    plt.ylabel('Average Absolute Error')\n",
    "    plt.title('Average Detection Error by Ground Truth Count')\n",
    "    plt.grid(True, linestyle='--', alpha=0.7)\n",
    "    \n",
    "    # 4. Pie chart of over-detection vs under-detection\n",
    "    plt.subplot(2, 2, 4)\n",
    "    over_detection = (eval_df['detection_diff'] > 0).sum()\n",
    "    under_detection = (eval_df['detection_diff'] < 0).sum()\n",
    "    exact_detection = (eval_df['detection_diff'] == 0).sum()\n",
    "    \n",
    "    labels = ['Over-detected', 'Under-detected', 'Exact Match']\n",
    "    sizes = [over_detection, under_detection, exact_detection]\n",
    "    colors = ['#ff9999', '#66b3ff', '#99ff99']\n",
    "    explode = (0.1, 0.1, 0.1)  # explode all slices for better visibility\n",
    "    \n",
    "    plt.pie(sizes, explode=explode, labels=labels, colors=colors, autopct='%1.1f%%', shadow=True, startangle=90)\n",
    "    plt.axis('equal')  # Equal aspect ratio ensures that pie is drawn as a circle\n",
    "    plt.title('Distribution of Detection Results')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Another useful visualization: Detection error by image\n",
    "    plt.figure(figsize=(15, 6))\n",
    "    \n",
    "    # Sort images by absolute error for better visualization\n",
    "    sorted_df = eval_df.sort_values('detection_error', ascending=False)\n",
    "    top_n = min(20, len(sorted_df))  # Show top 20 or less if fewer images\n",
    "    \n",
    "    plt.bar(range(top_n), sorted_df['detection_error'].head(top_n), color='skyblue')\n",
    "    plt.xticks(range(top_n), sorted_df['filename'].head(top_n), rotation=90)\n",
    "    plt.xlabel('Image Filename')\n",
    "    plt.ylabel('Absolute Detection Error')\n",
    "    plt.title(f'Top {top_n} Images with Highest Detection Error')\n",
    "    plt.grid(True, axis='y', linestyle='--', alpha=0.7)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # One more visualization: ROC-like curve (if we consider detection as binary classification)\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    \n",
    "    # Create thresholds for error tolerance\n",
    "    error_thresholds = [0, 1, 2, 3, 4, 5, 10]\n",
    "    accuracy_rates = []\n",
    "    \n",
    "    for threshold in error_thresholds:\n",
    "        # Count images where error is less than or equal to threshold\n",
    "        accurate_count = (eval_df['detection_error'] <= threshold).sum()\n",
    "        accuracy_rate = accurate_count / len(eval_df) * 100\n",
    "        accuracy_rates.append(accuracy_rate)\n",
    "    \n",
    "    plt.plot(error_thresholds, accuracy_rates, marker='o', linestyle='-', linewidth=2)\n",
    "    plt.xlabel('Error Tolerance Threshold')\n",
    "    plt.ylabel('Accuracy Rate (%)')\n",
    "    plt.title('Accuracy Rate by Error Tolerance')\n",
    "    plt.grid(True, linestyle='--', alpha=0.7)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"No evaluation results available for visualization\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67938af0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to evaluate min_area parameter\n",
    "def evaluate_min_area_parameter(test_images, test_annotations, min_area_values):\n",
    "    \"\"\"Evaluate different min_area values against ground truth\"\"\"\n",
    "    results = []\n",
    "    \n",
    "    for min_area in tqdm(min_area_values, desc=\"Evaluating min_area values\"):\n",
    "        print(f\"\\nEvaluating min_area = {min_area}...\")\n",
    "        total_gt_objects = 0\n",
    "        total_detected_objects = 0\n",
    "        total_abs_error = 0\n",
    "        \n",
    "        for filename, file_path in test_images:\n",
    "            # Get ground truth count\n",
    "            gt_count = test_annotations.get(filename, 0)\n",
    "            total_gt_objects += gt_count\n",
    "            \n",
    "            # Run detector with current min_area\n",
    "            detection_results = evaluate_image_with_detector(file_path, min_area=min_area)\n",
    "            \n",
    "            if detection_results is not None:\n",
    "                detected_count = detection_results['total']\n",
    "                total_detected_objects += detected_count\n",
    "                total_abs_error += abs(detected_count - gt_count)\n",
    "        \n",
    "        # Calculate metrics\n",
    "        num_images = len(test_images)\n",
    "        avg_error = total_abs_error / num_images if num_images > 0 else float('inf')\n",
    "        total_diff = total_detected_objects - total_gt_objects\n",
    "        \n",
    "        # Store results\n",
    "        results.append({\n",
    "            'min_area': min_area,\n",
    "            'total_gt_objects': total_gt_objects,\n",
    "            'total_detected_objects': total_detected_objects,\n",
    "            'total_diff': total_diff,\n",
    "            'total_abs_error': total_abs_error,\n",
    "            'avg_abs_error': avg_error\n",
    "        })\n",
    "        \n",
    "        print(f\"  Total GT Objects: {total_gt_objects}\")\n",
    "        print(f\"  Total Detected Objects: {total_detected_objects}\")\n",
    "        print(f\"  Average Absolute Error: {avg_error:.2f}\")\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Let's evaluate a subset of images to save time\n",
    "run_parameter_tuning = True  # Set to True to run the parameter tuning\n",
    "\n",
    "if run_parameter_tuning and 'test_image_files' in locals() and test_annotations:\n",
    "    # Define min_area values to test\n",
    "    min_area_values_to_test = [400, 500, 750, 1000, 1500, 2000, 2500]\n",
    "    \n",
    "    # Select a subset of images for faster evaluation\n",
    "    max_images_for_tuning = 10  # Adjust based on your time constraints\n",
    "    test_subset = test_image_files[:max_images_for_tuning]\n",
    "    \n",
    "    print(f\"Running parameter tuning on {len(test_subset)} images...\")\n",
    "    tuning_results = evaluate_min_area_parameter(test_subset, test_annotations, min_area_values_to_test)\n",
    "    \n",
    "    # Convert to DataFrame\n",
    "    tuning_df = pd.DataFrame(tuning_results)\n",
    "    \n",
    "    # Visualize the tuning results\n",
    "    plt.figure(figsize=(15, 10))\n",
    "    \n",
    "    # 1. Plot absolute error vs min_area\n",
    "    plt.subplot(2, 2, 1)\n",
    "    plt.plot(tuning_df['min_area'], tuning_df['avg_abs_error'], marker='o', linestyle='-')\n",
    "    plt.xlabel('Minimum Area Threshold')\n",
    "    plt.ylabel('Average Absolute Error')\n",
    "    plt.title('Average Error vs. Min Area Threshold')\n",
    "    plt.grid(True, linestyle='--', alpha=0.7)\n",
    "    \n",
    "    # 2. Plot total objects detected vs min_area\n",
    "    plt.subplot(2, 2, 2)\n",
    "    plt.plot(tuning_df['min_area'], tuning_df['total_detected_objects'], marker='o', linestyle='-', label='Detected')\n",
    "    plt.axhline(y=tuning_df['total_gt_objects'].iloc[0], color='r', linestyle='--', label='Ground Truth')\n",
    "    plt.xlabel('Minimum Area Threshold')\n",
    "    plt.ylabel('Total Objects Count')\n",
    "    plt.title('Total Objects Detected vs. Min Area Threshold')\n",
    "    plt.legend()\n",
    "    plt.grid(True, linestyle='--', alpha=0.7)\n",
    "    \n",
    "    # 3. Bar chart of error by min_area\n",
    "    plt.subplot(2, 2, 3)\n",
    "    plt.bar(tuning_df['min_area'].astype(str), tuning_df['total_abs_error'])\n",
    "    plt.xlabel('Minimum Area Threshold')\n",
    "    plt.ylabel('Total Absolute Error')\n",
    "    plt.title('Total Error vs. Min Area Threshold')\n",
    "    plt.grid(True, axis='y', linestyle='--', alpha=0.7)\n",
    "    \n",
    "    # 4. Line chart of total_diff by min_area (negative means under-detection, positive means over-detection)\n",
    "    plt.subplot(2, 2, 4)\n",
    "    plt.plot(tuning_df['min_area'], tuning_df['total_diff'], marker='o', linestyle='-')\n",
    "    plt.axhline(y=0, color='r', linestyle='--', label='Perfect Match')\n",
    "    plt.xlabel('Minimum Area Threshold')\n",
    "    plt.ylabel('Total Difference (Detected - GT)')\n",
    "    plt.title('Detection Bias vs. Min Area Threshold')\n",
    "    plt.grid(True, linestyle='--', alpha=0.7)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Find the best min_area value based on average absolute error\n",
    "    best_min_area = tuning_df.loc[tuning_df['avg_abs_error'].idxmin(), 'min_area']\n",
    "    print(f\"\\nBest min_area value based on evaluation: {best_min_area}\")\n",
    "    print(f\"Corresponding average absolute error: {tuning_df['avg_abs_error'].min():.2f} objects\")\n",
    "else:\n",
    "    print(\"Parameter tuning skipped. Set run_parameter_tuning=True to enable.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "c-venv-gobn-cv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
